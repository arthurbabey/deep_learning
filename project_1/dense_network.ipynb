{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import dlc_practical_prologue as prolog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_errors(pred, truth):\n",
    "    \n",
    "    pred_class = pred.argmax(1)\n",
    "    return (pred_class - truth != 0).sum().item()\n",
    "\n",
    "def nb_errors_aux(pred, truth):\n",
    "    \n",
    "    pred_class = pred.view(-1, 2, 10).argmax(2).argmax(1)\n",
    "    return (pred_class - truth != 0).sum().item()\n",
    "\n",
    "def train_model(model, train_input, train_target, test_input, test_target,  epochs=250, batch_size=100, lr=0.1):\n",
    "    \n",
    "    for i in range(0,len(model),2):\n",
    "        torch.nn.init.xavier_uniform_(model[i].weight)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    test_accuracy = []\n",
    "    best_accuracy = 0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        for b in range(0, train_input.size(0), batch_size):\n",
    "            output = model(train_input.narrow(0, b, batch_size))\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "            loss = criterion(output, train_target.narrow(0, b, batch_size))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        output_train = model(train_input)\n",
    "        output_test = model(test_input)\n",
    "        train_loss.append(criterion(output_train, train_target).item())\n",
    "        test_loss.append(criterion(output_test, test_target).item())\n",
    "        accuracy = 1 - nb_errors(output_test, test_target) / 1000\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_epoch = i+1\n",
    "        test_accuracy.append(accuracy)\n",
    "        \n",
    "    return train_loss, test_loss, test_accuracy, best_accuracy\n",
    "\n",
    "def train_model_aux(model, train_input, train_classes, test_input, test_target, test_classes,\\\n",
    "                epochs=250, batch_size=100, lr=0.1):\n",
    "    \n",
    "    for i in range(0,len(model),2):\n",
    "        torch.nn.init.xavier_uniform_(model[i].weight)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    test_accuracy = []\n",
    "    best_accuracy = 0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        for b in range(0, train_input.size(0), batch_size):\n",
    "            output = model(train_input.narrow(0, b, batch_size))\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "            loss = criterion(output, train_classes.narrow(0, b, batch_size))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        output_train = model(train_input)\n",
    "        output_test = model(test_input)\n",
    "        train_loss.append(criterion(output_train, train_classes).item())\n",
    "        test_loss.append(criterion(output_test, test_classes).item())\n",
    "        accuracy = 1 - nb_errors_aux(output_test, test_target) / 1000\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_epoch = i+1\n",
    "        test_accuracy.append(accuracy)\n",
    "       \n",
    "    return train_loss, test_loss, test_accuracy, best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 2*14*14\n",
    "output_dim = 2\n",
    "\n",
    "model1 = nn.Sequential(nn.Linear(input_dim, 128), nn.ReLU(), nn.Linear(128, output_dim))\n",
    "\n",
    "model2 = nn.Sequential(nn.Linear(input_dim, 256), nn.ReLU(), nn.Linear(256, output_dim))\n",
    "\n",
    "model3 = nn.Sequential(nn.Linear(input_dim, 512), nn.ReLU(), nn.Linear(512, output_dim))\n",
    "\n",
    "model4 = nn.Sequential(nn.Linear(input_dim, 1024), nn.ReLU(), nn.Linear(1024, output_dim))\n",
    "\n",
    "model5 = nn.Sequential(nn.Linear(input_dim, 128), nn.ReLU(), nn.Linear(128, 256), nn.ReLU(), \\\n",
    "                       nn.Linear(256, output_dim))\n",
    "\n",
    "model6 = nn.Sequential(nn.Linear(input_dim, 256), nn.ReLU(), nn.Linear(256, 512), nn.ReLU(), \\\n",
    "                       nn.Linear(512, output_dim))\n",
    "\n",
    "model7 = nn.Sequential(nn.Linear(input_dim, 512), nn.ReLU(), nn.Linear(512, 1024), nn.ReLU(), \\\n",
    "                       nn.Linear(1024, output_dim))\n",
    "\n",
    "model8 = nn.Sequential(nn.Linear(input_dim, 128), nn.ReLU(), nn.Linear(128, 256), nn.ReLU(), nn.Linear(256, 512),\\\n",
    "                       nn.ReLU(), nn.Linear(512, output_dim))\n",
    "\n",
    "model9 = nn.Sequential(nn.Linear(input_dim, 256), nn.ReLU(), nn.Linear(256, 512), nn.ReLU(), nn.Linear(512, 1024),\\\n",
    "                       nn.ReLU(), nn.Linear(1024, output_dim))\n",
    "\n",
    "model10 = nn.Sequential(nn.Linear(input_dim, 128), nn.ReLU(), nn.Linear(128, 256), nn.ReLU(), nn.Linear(256, 512),\\\n",
    "                       nn.ReLU(), nn.Linear(512, 1024), nn.ReLU(), nn.Linear(1024, output_dim))\n",
    "\n",
    "model11 = nn.Sequential(nn.Linear(input_dim, 64), nn.ReLU(), nn.Linear(64, 128), nn.ReLU(), nn.Linear(128, 256),\\\n",
    "                       nn.ReLU(), nn.Linear(256, 512), nn.ReLU(), nn.Linear(512, output_dim))\n",
    "\n",
    "model12 = nn.Sequential(nn.Linear(input_dim, 256), nn.ReLU(), nn.Linear(256, 512), nn.ReLU(), nn.Linear(512, 1024),\\\n",
    "                       nn.ReLU(), nn.Linear(1024, 2048), nn.ReLU(), nn.Linear(2048, output_dim))\n",
    "\n",
    "model13 = nn.Sequential(nn.Linear(input_dim, 64), nn.ReLU(), nn.Linear(64, 128), nn.ReLU(), nn.Linear(128, 256),\\\n",
    "                       nn.ReLU(), nn.Linear(256, 512), nn.ReLU(), nn.Linear(512, 1024), nn.ReLU(), \\\n",
    "                        nn.Linear(1024, output_dim))\n",
    "\n",
    "model14 = nn.Sequential(nn.Linear(input_dim, 128), nn.ReLU(), nn.Linear(128, 256), nn.ReLU(), nn.Linear(256, 512),\\\n",
    "                       nn.ReLU(), nn.Linear(512, 1024), nn.ReLU(), nn.Linear(1024, 2048), nn.ReLU(), \\\n",
    "                        nn.Linear(2048, output_dim))\n",
    "\n",
    "model15 = nn.Sequential(nn.Linear(input_dim, 256), nn.ReLU(), nn.Linear(256, 512), nn.ReLU(), nn.Linear(512, 1024),\\\n",
    "                       nn.ReLU(), nn.Linear(1024, 2048), nn.ReLU(), nn.Linear(2048, 4096), nn.ReLU(), \\\n",
    "                        nn.Linear(4096, output_dim))\n",
    "\n",
    "models = [model1, model2, model3, model4, model5, model6, model7, model8, model9, model10, model11, model12,\\\n",
    "          model13, model14, model15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "accuracies = torch.empty(15, 10, dtype=torch.float)\n",
    "\n",
    "for i in range(10):\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = prolog.generate_pair_sets(1000)\n",
    "    train_input_direct = train_input.view(-1, input_dim)\n",
    "    test_input_direct = test_input.view(-1, input_dim)\n",
    "    for j in range(15):\n",
    "        _, _, _, best_accuracy = train_model(models[j], train_input_direct, train_target, test_input_direct,\\\n",
    "                                             test_target, epochs=epochs)\n",
    "        accuracies[j][i] = best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 14*14\n",
    "output_dim = 10\n",
    "\n",
    "model1 = nn.Sequential(nn.Linear(input_dim, 128), nn.ReLU(), nn.Linear(128, output_dim))\n",
    "\n",
    "model2 = nn.Sequential(nn.Linear(input_dim, 256), nn.ReLU(), nn.Linear(256, output_dim))\n",
    "\n",
    "model3 = nn.Sequential(nn.Linear(input_dim, 512), nn.ReLU(), nn.Linear(512, output_dim))\n",
    "\n",
    "model4 = nn.Sequential(nn.Linear(input_dim, 1024), nn.ReLU(), nn.Linear(1024, output_dim))\n",
    "\n",
    "model5 = nn.Sequential(nn.Linear(input_dim, 128), nn.ReLU(), nn.Linear(128, 256), nn.ReLU(), \\\n",
    "                       nn.Linear(256, output_dim))\n",
    "\n",
    "model6 = nn.Sequential(nn.Linear(input_dim, 256), nn.ReLU(), nn.Linear(256, 512), nn.ReLU(), \\\n",
    "                       nn.Linear(512, output_dim))\n",
    "\n",
    "model7 = nn.Sequential(nn.Linear(input_dim, 512), nn.ReLU(), nn.Linear(512, 1024), nn.ReLU(), \\\n",
    "                       nn.Linear(1024, output_dim))\n",
    "\n",
    "model8 = nn.Sequential(nn.Linear(input_dim, 128), nn.ReLU(), nn.Linear(128, 256), nn.ReLU(), nn.Linear(256, 512),\\\n",
    "                       nn.ReLU(), nn.Linear(512, output_dim))\n",
    "\n",
    "model9 = nn.Sequential(nn.Linear(input_dim, 256), nn.ReLU(), nn.Linear(256, 512), nn.ReLU(), nn.Linear(512, 1024),\\\n",
    "                       nn.ReLU(), nn.Linear(1024, output_dim))\n",
    "\n",
    "model10 = nn.Sequential(nn.Linear(input_dim, 128), nn.ReLU(), nn.Linear(128, 256), nn.ReLU(), nn.Linear(256, 512),\\\n",
    "                       nn.ReLU(), nn.Linear(512, 1024), nn.ReLU(), nn.Linear(1024, output_dim))\n",
    "\n",
    "model11 = nn.Sequential(nn.Linear(input_dim, 64), nn.ReLU(), nn.Linear(64, 128), nn.ReLU(), nn.Linear(128, 256),\\\n",
    "                       nn.ReLU(), nn.Linear(256, 512), nn.ReLU(), nn.Linear(512, output_dim))\n",
    "\n",
    "model12 = nn.Sequential(nn.Linear(input_dim, 256), nn.ReLU(), nn.Linear(256, 512), nn.ReLU(), nn.Linear(512, 1024),\\\n",
    "                       nn.ReLU(), nn.Linear(1024, 2048), nn.ReLU(), nn.Linear(2048, output_dim))\n",
    "\n",
    "model13 = nn.Sequential(nn.Linear(input_dim, 64), nn.ReLU(), nn.Linear(64, 128), nn.ReLU(), nn.Linear(128, 256),\\\n",
    "                       nn.ReLU(), nn.Linear(256, 512), nn.ReLU(), nn.Linear(512, 1024), nn.ReLU(), \\\n",
    "                        nn.Linear(1024, output_dim))\n",
    "\n",
    "model14 = nn.Sequential(nn.Linear(input_dim, 128), nn.ReLU(), nn.Linear(128, 256), nn.ReLU(), nn.Linear(256, 512),\\\n",
    "                       nn.ReLU(), nn.Linear(512, 1024), nn.ReLU(), nn.Linear(1024, 2048), nn.ReLU(), \\\n",
    "                        nn.Linear(2048, output_dim))\n",
    "\n",
    "model15 = nn.Sequential(nn.Linear(input_dim, 256), nn.ReLU(), nn.Linear(256, 512), nn.ReLU(), nn.Linear(512, 1024),\\\n",
    "                       nn.ReLU(), nn.Linear(1024, 2048), nn.ReLU(), nn.Linear(2048, 4096), nn.ReLU(), \\\n",
    "                        nn.Linear(4096, output_dim))\n",
    "\n",
    "models = [model1, model2, model3, model4, model5, model6, model7, model8, model9, model10, model11, model12,\\\n",
    "          model13, model14, model15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "accuracies_aux = torch.empty(15, 10, dtype=torch.float)\n",
    "\n",
    "for i in range(10):\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = prolog.generate_pair_sets(1000)\n",
    "    train_input_aux = train_input.view(-1, input_dim)\n",
    "    test_input_aux = test_input.view(-1, input_dim)\n",
    "    train_classes_aux = train_classes.view(2000)\n",
    "    test_classes_aux = test_classes.view(2000)\n",
    "    for j in range(15):\n",
    "        _, _, _, best_accuracy = train_model_aux(models[j], train_input_aux, train_classes_aux, \\\n",
    "                                                       test_input_aux, test_target, test_classes_aux, \\\n",
    "                                                       epochs=epochs)\n",
    "        accuracies_aux[j][i] = best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7628, 0.7782, 0.8028, 0.8031, 0.7536, 0.7677, 0.7823, 0.7497, 0.7651,\n",
       "        0.7453, 0.7149, 0.7713, 0.7168, 0.7519, 0.7849])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0142, 0.0198, 0.0119, 0.0211, 0.0152, 0.0150, 0.0120, 0.0187, 0.0136,\n",
       "        0.0135, 0.0169, 0.0156, 0.0216, 0.0167, 0.0079])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.median(\n",
       "values=tensor([0.7580, 0.7800, 0.8030, 0.8090, 0.7570, 0.7720, 0.7790, 0.7500, 0.7600,\n",
       "        0.7420, 0.7170, 0.7710, 0.7230, 0.7550, 0.7850]),\n",
       "indices=tensor([9, 1, 6, 5, 4, 7, 9, 3, 1, 1, 6, 2, 2, 8, 3]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.median(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.7880, 0.8070, 0.8180, 0.8240, 0.7810, 0.7880, 0.8120, 0.7840, 0.7870,\n",
       "        0.7660, 0.7400, 0.7940, 0.7340, 0.7680, 0.7990]),\n",
       "indices=tensor([2, 6, 9, 6, 6, 3, 6, 2, 6, 5, 0, 6, 3, 7, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([0.7410, 0.7460, 0.7820, 0.7520, 0.7240, 0.7360, 0.7670, 0.7130, 0.7450,\n",
       "        0.7220, 0.6880, 0.7410, 0.6650, 0.7090, 0.7730]),\n",
       "indices=tensor([8, 8, 1, 8, 9, 4, 8, 4, 0, 3, 3, 8, 9, 9, 8]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.min(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3 and 4 seem to be the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9176, 0.9294, 0.9485, 0.9563, 0.9238, 0.9427, 0.9497, 0.9308, 0.9447,\n",
       "        0.9334, 0.9152, 0.9468, 0.9153, 0.9351, 0.9543])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies_aux.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0086, 0.0073, 0.0073, 0.0046, 0.0084, 0.0043, 0.0089, 0.0082, 0.0034,\n",
       "        0.0093, 0.0105, 0.0071, 0.0061, 0.0079, 0.0059])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies_aux.std(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.median(\n",
       "values=tensor([0.9160, 0.9290, 0.9490, 0.9570, 0.9220, 0.9430, 0.9530, 0.9320, 0.9430,\n",
       "        0.9310, 0.9130, 0.9460, 0.9150, 0.9350, 0.9530]),\n",
       "indices=tensor([9, 4, 5, 5, 3, 6, 4, 3, 3, 7, 9, 0, 7, 5, 7]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies_aux.median(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.9320, 0.9420, 0.9600, 0.9640, 0.9410, 0.9500, 0.9600, 0.9450, 0.9500,\n",
       "        0.9460, 0.9280, 0.9620, 0.9260, 0.9450, 0.9640]),\n",
       "indices=tensor([8, 0, 9, 8, 8, 8, 9, 8, 1, 8, 6, 8, 6, 0, 8]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies_aux.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([0.9060, 0.9200, 0.9350, 0.9480, 0.9130, 0.9350, 0.9330, 0.9160, 0.9410,\n",
       "        0.9140, 0.8940, 0.9380, 0.9080, 0.9220, 0.9460]),\n",
       "indices=tensor([7, 3, 4, 7, 2, 1, 2, 1, 2, 1, 8, 4, 3, 2, 4]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies_aux.min(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 4 seems to be the best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
