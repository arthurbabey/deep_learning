{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "conv_net.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthurbabey/deep_learning/blob/master/project_1/conv_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL9c0tnT_9nV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IywA-9e2ADaO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db0ef13b-96d9-479b-c19e-a5fad9b83363"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jxszVuaBB5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "import dlc_practical_prologue as prolog\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDhJtuEB_9ne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nb_errors(pred, truth):\n",
        "    \n",
        "    pred_class = pred.argmax(1)\n",
        "    return (pred_class - truth != 0).sum().item()\n",
        "\n",
        "def nb_errors_aux(pred, truth):\n",
        "    \n",
        "    pred_class = pred.view(-1, 2, 10).argmax(2).argmax(1)\n",
        "    return (pred_class - truth != 0).sum().item()\n",
        "        \n",
        "    \n",
        "def train_model(model, train_input, train_target, test_input, test_target,  epochs=500, batch_size=100, lr=0.1):\n",
        "\n",
        "    torch.nn.init.xavier_uniform_(model.conv1.weight)\n",
        "    torch.nn.init.xavier_uniform_(model.conv2.weight)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    #scheduler = StepLR(optimizer, step_size=100, gamma=0.1)\n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    test_accuracy = []\n",
        "    best_accuracy = 0\n",
        "    best_epoch = 0\n",
        "    \n",
        "    for i in range(epochs):\n",
        "        model.train()\n",
        "      \n",
        "        for b in range(0, train_input.size(0), batch_size):\n",
        "            output = model(train_input.narrow(0, b, batch_size))\n",
        "            criterion = torch.nn.CrossEntropyLoss()\n",
        "            loss = criterion(output, train_target.narrow(0, b, batch_size))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            #scheduler.step()\n",
        "\n",
        "        output_train = model(train_input)\n",
        "        model.eval()\n",
        "        output_test = model(test_input)\n",
        "        train_loss.append(criterion(output_train, train_target).item())\n",
        "        test_loss.append(criterion(output_test, test_target).item())\n",
        "        accuracy = 1 - nb_errors(output_test, test_target) / 1000\n",
        "        \n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_epoch = i+1\n",
        "        test_accuracy.append(accuracy)\n",
        "        \n",
        "        if i%100 == 0:\n",
        "            print('Epoch : ',i+1, '\\t', 'test loss :', test_loss[-1], '\\t', 'train loss', train_loss[-1])\n",
        "        \n",
        "    return train_loss, test_loss, test_accuracy, best_accuracy\n",
        "\n",
        "\n",
        "\n",
        "def train_model_aux(model, train_input, train_classes, test_input, test_target, test_classes,\\\n",
        "                epochs=250, batch_size=100, lr=0.1):\n",
        "    \n",
        "    torch.nn.init.xavier_uniform_(model.conv1.weight)\n",
        "    torch.nn.init.xavier_uniform_(model.conv2.weight)\n",
        "        \n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    test_accuracy = []\n",
        "    best_accuracy = 0\n",
        "    best_epoch = 0\n",
        "    \n",
        "    for i in range(epochs):\n",
        "        for b in range(0, train_input.size(0), batch_size):\n",
        "            output = model(train_input.narrow(0, b, batch_size))\n",
        "            criterion = torch.nn.CrossEntropyLoss()\n",
        "            loss = criterion(output, train_classes.narrow(0, b, batch_size))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        output_train = model(train_input)\n",
        "        output_test = model(test_input)\n",
        "        train_loss.append(criterion(output_train, train_classes).item())\n",
        "        test_loss.append(criterion(output_test, test_classes).item())\n",
        "        accuracy = 1 - nb_errors_aux(output_test, test_target) / 1000\n",
        "        \n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_epoch = i+1\n",
        "        test_accuracy.append(accuracy)\n",
        "\n",
        "        if i%100 == 0:\n",
        "            print('Epoch : ',i+1, '\\t', 'test loss :', test_loss[-1], '\\t', 'train loss', train_loss[-1])\n",
        "       \n",
        "    return train_loss, test_loss, test_accuracy, best_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUb1th3K_9nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNet3(nn.Module):\n",
        "    def __init__(self, nb_hidden):\n",
        "        super(ConvNet3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 2, out_channels = 4, kernel_size=2, stride = 1)\n",
        "        self.conv2 = nn.Conv2d(4, 8, kernel_size=3, stride = 1, padding=2)\n",
        "        self.conv3 = nn.Conv2d(8, 16, kernel_size = 3, stride = 1, padding=2)\n",
        "        self.fc1 = nn.Linear(16*3*3, nb_hidden)\n",
        "        self.fc2 = nn.Linear(nb_hidden, 2)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = x.view(-1, 16*3*3)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSSrNaWt_9nm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNet2(nn.Module):\n",
        "    def __init__(self, nb_hidden, i = 1):\n",
        "        super(ConvNet2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 2, out_channels = 4, kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(4, 8, kernel_size=2, stride = 1)\n",
        "        self.fc1 = nn.Linear(32, nb_hidden)\n",
        "        self.fc2 = nn.Linear(nb_hidden, 2)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), (2, 2)))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = x.view(-1, 32)\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2vJLlIoOeI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNetAux(nn.Module):\n",
        "    def __init__(self, nb_hidden):\n",
        "        super(ConvNetAux, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 4, kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(4, 8, kernel_size=2, stride = 1)\n",
        "        self.fc1 = nn.Linear(32, nb_hidden)\n",
        "        self.fc2 = nn.Linear(nb_hidden, 10)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), (2, 2)))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = x.view(-1, 32)\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muEWGibEIxj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = ConvNet2(3)\n",
        "model2 = ConvNet2(6)\n",
        "model3 = ConvNet2(10)\n",
        "model4 = ConvNet2(15)\n",
        "model5 = ConvNet2(20)\n",
        "model6 = ConvNet2(50)\n",
        "model7 = ConvNet2(80)\n",
        "model8 = ConvNet2(120)\n",
        "model9 = ConvNet2(200)\n",
        "model10 = ConvNet2(1000)\n",
        "\n",
        "\n",
        "model11 = ConvNet3(3)\n",
        "model12 = ConvNet3(6)\n",
        "model13= ConvNet3(10)\n",
        "model14 = ConvNet3(20)\n",
        "model15 = ConvNet3(35)\n",
        "model16 = ConvNet3(70)\n",
        "model17 = ConvNet3(100)\n",
        "model18 = ConvNet3(150)\n",
        "model19 = ConvNet3(250)\n",
        "model20 = ConvNet3(1000)\n",
        "\n",
        "\n",
        "aux1 = ConvNetAux(5)\n",
        "aux2 = ConvNetAux(10)\n",
        "aux3 = ConvNetAux(20)\n",
        "aux4 = ConvNetAux(50)\n",
        "aux5 = ConvNetAux(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-Tuzg3l_9oJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = [model1, model2, model3, model4, model5, model6, model7, model8, model9, model10, model11, model12, model13, model14,\n",
        "          model15, model16, model17, model18, model19, model20]\n",
        "\n",
        "auxs = [aux1, aux2, aux3, aux4, aux5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZhV8lXbB1wb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ff645b5-b82b-4dd4-b36f-2687573779a2"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\") \n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")\n",
        "\n",
        "for model in models:\n",
        "    model.to(device)\n",
        "\n",
        "for aux in auxs: \n",
        "    aux.to(device)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on the GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUVGAObB_9oN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2e9563c9-c9f2-411c-9ab3-ba43f73dc0c0"
      },
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "epochs = 200\n",
        "accuracies = torch.empty(20, 4, dtype=torch.float)\n",
        "\n",
        "for i in range(4):\n",
        "    train_input, train_target, train_classes, test_input, test_target, test_classes = prolog.generate_pair_sets(1000)\n",
        "    train_input = train_input.cuda()\n",
        "    train_target = train_target.cuda()\n",
        "    test_input = test_input.cuda()\n",
        "    test_target = test_target.cuda()\n",
        "\n",
        "    for j in range(20):\n",
        "        _, _, _, best_accuracy = train_model(models[j], train_input, train_target, test_input,\\\n",
        "                                             test_target, epochs=epochs, lr = 0.005)\n",
        "        print('Model', j+1 , best_accuracy)\n",
        "        accuracies[j][i] = best_accuracy\n",
        "\n",
        "\n",
        "minute = (time.time()-start) / 60\n",
        "print('It took', minute, 'minutes.')\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch :  1 \t test loss : 0.6918238401412964 \t train loss 0.6975423693656921\n",
            "Epoch :  101 \t test loss : 0.6659956574440002 \t train loss 0.6723462343215942\n",
            "Model 1 0.552\n",
            "Epoch :  1 \t test loss : 0.6877380013465881 \t train loss 0.687165379524231\n",
            "Epoch :  101 \t test loss : 0.6877829432487488 \t train loss 0.6861211061477661\n",
            "Model 2 0.702\n",
            "Epoch :  1 \t test loss : 0.6921951770782471 \t train loss 0.7684497833251953\n",
            "Epoch :  101 \t test loss : 0.647911012172699 \t train loss 0.679916262626648\n",
            "Model 3 0.726\n",
            "Epoch :  1 \t test loss : 0.6851949095726013 \t train loss 0.6833269000053406\n",
            "Epoch :  101 \t test loss : 0.5831524729728699 \t train loss 0.6495051383972168\n",
            "Model 4 0.753\n",
            "Epoch :  1 \t test loss : 0.6997272968292236 \t train loss 0.7665861248970032\n",
            "Epoch :  101 \t test loss : 0.6234093308448792 \t train loss 0.6478978991508484\n",
            "Model 5 0.736\n",
            "Epoch :  1 \t test loss : 0.6853013634681702 \t train loss 0.6909220218658447\n",
            "Epoch :  101 \t test loss : 0.579643189907074 \t train loss 0.6054800152778625\n",
            "Model 6 0.745\n",
            "Epoch :  1 \t test loss : 0.7051042914390564 \t train loss 0.9507387280464172\n",
            "Epoch :  101 \t test loss : 0.6039142608642578 \t train loss 0.6338663697242737\n",
            "Model 7 0.733\n",
            "Epoch :  1 \t test loss : 0.7047733068466187 \t train loss 1.6088465452194214\n",
            "Epoch :  101 \t test loss : 0.6469348073005676 \t train loss 0.6405312418937683\n",
            "Model 8 0.726\n",
            "Epoch :  1 \t test loss : 0.6674709916114807 \t train loss 0.9645593762397766\n",
            "Epoch :  101 \t test loss : 0.5804932713508606 \t train loss 0.5985825657844543\n",
            "Model 9 0.769\n",
            "Epoch :  1 \t test loss : 0.8468169569969177 \t train loss 1.7458810806274414\n",
            "Epoch :  101 \t test loss : 0.5821595191955566 \t train loss 0.598695695400238\n",
            "Model 10 0.741\n",
            "Epoch :  1 \t test loss : 0.689280092716217 \t train loss 0.7437483072280884\n",
            "Epoch :  101 \t test loss : 0.6877778768539429 \t train loss 0.6865765452384949\n",
            "Model 11 0.552\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.7001091241836548\n",
            "Epoch :  101 \t test loss : 0.7914363741874695 \t train loss 0.31889593601226807\n",
            "Model 12 0.74\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.7186100482940674\n",
            "Epoch :  101 \t test loss : 0.5656816363334656 \t train loss 0.4021811783313751\n",
            "Model 13 0.747\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.7007455825805664\n",
            "Epoch :  101 \t test loss : 0.7426345348358154 \t train loss 0.25008586049079895\n",
            "Model 14 0.763\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.7139111757278442\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931708455085754\n",
            "Model 15 0.552\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.7027256488800049\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 16 0.552\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6934729218482971\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 17 0.552\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 18 0.552\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6978203058242798\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 19 0.552\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 20 0.552\n",
            "Epoch :  1 \t test loss : 0.6890454292297363 \t train loss 0.7038470506668091\n",
            "Epoch :  101 \t test loss : 0.6542983651161194 \t train loss 0.6591647267341614\n",
            "Model 1 0.5569999999999999\n",
            "Epoch :  1 \t test loss : 0.6914089918136597 \t train loss 0.6853319406509399\n",
            "Epoch :  101 \t test loss : 0.6149874329566956 \t train loss 0.6389901041984558\n",
            "Model 2 0.719\n",
            "Epoch :  1 \t test loss : 0.6978881359100342 \t train loss 0.6991074681282043\n",
            "Epoch :  101 \t test loss : 0.6115555167198181 \t train loss 0.6207044720649719\n",
            "Model 3 0.726\n",
            "Epoch :  1 \t test loss : 0.6977429986000061 \t train loss 0.8024404048919678\n",
            "Epoch :  101 \t test loss : 0.6161642670631409 \t train loss 0.6243176460266113\n",
            "Model 4 0.712\n",
            "Epoch :  1 \t test loss : 0.6881019473075867 \t train loss 0.6927137970924377\n",
            "Epoch :  101 \t test loss : 0.5961388349533081 \t train loss 0.6194932460784912\n",
            "Model 5 0.739\n",
            "Epoch :  1 \t test loss : 0.687055230140686 \t train loss 0.7301574349403381\n",
            "Epoch :  101 \t test loss : 0.5878341794013977 \t train loss 0.595775842666626\n",
            "Model 6 0.729\n",
            "Epoch :  1 \t test loss : 0.6915644407272339 \t train loss 0.7153950333595276\n",
            "Epoch :  101 \t test loss : 0.5664046406745911 \t train loss 0.5539143681526184\n",
            "Model 7 0.733\n",
            "Epoch :  1 \t test loss : 0.7072502374649048 \t train loss 0.7601199150085449\n",
            "Epoch :  101 \t test loss : 0.5930556654930115 \t train loss 0.6149560809135437\n",
            "Model 8 0.731\n",
            "Epoch :  1 \t test loss : 0.6824619174003601 \t train loss 0.8030756711959839\n",
            "Epoch :  101 \t test loss : 0.5887481570243835 \t train loss 0.6072773933410645\n",
            "Model 9 0.721\n",
            "Epoch :  1 \t test loss : 0.9614328145980835 \t train loss 2.8597493171691895\n",
            "Epoch :  101 \t test loss : 0.6237180829048157 \t train loss 0.6142675280570984\n",
            "Model 10 0.721\n",
            "Epoch :  1 \t test loss : 0.6866356134414673 \t train loss 0.6858747005462646\n",
            "Epoch :  101 \t test loss : 0.6868816018104553 \t train loss 0.6838706731796265\n",
            "Model 11 0.5569999999999999\n",
            "Epoch :  1 \t test loss : 1.0339642763137817 \t train loss 1.053439974784851\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.7364991307258606\n",
            "Model 12 0.5569999999999999\n",
            "Epoch :  1 \t test loss : 0.7452788949012756 \t train loss 0.9281142950057983\n",
            "Epoch :  101 \t test loss : 0.7726768851280212 \t train loss 0.48056185245513916\n",
            "Model 13 0.735\n",
            "Epoch :  1 \t test loss : 1.1552009582519531 \t train loss 1.3151559829711914\n",
            "Epoch :  101 \t test loss : 0.7788108587265015 \t train loss 0.2687138020992279\n",
            "Model 14 0.729\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6933307647705078\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 15 0.5569999999999999\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 16 0.5569999999999999\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 17 0.5569999999999999\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 18 0.5569999999999999\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 19 0.5569999999999999\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 20 0.5569999999999999\n",
            "Epoch :  1 \t test loss : 0.6911466717720032 \t train loss 0.6922672390937805\n",
            "Epoch :  101 \t test loss : 0.6120166182518005 \t train loss 0.6255974769592285\n",
            "Model 1 0.758\n",
            "Epoch :  1 \t test loss : 0.7680811285972595 \t train loss 0.9021344780921936\n",
            "Epoch :  101 \t test loss : 0.6470866799354553 \t train loss 0.6470411419868469\n",
            "Model 2 0.6779999999999999\n",
            "Epoch :  1 \t test loss : 0.7004867196083069 \t train loss 0.7115224599838257\n",
            "Epoch :  101 \t test loss : 0.6072478294372559 \t train loss 0.6268969774246216\n",
            "Model 3 0.7\n",
            "Epoch :  1 \t test loss : 0.6911042332649231 \t train loss 0.6859301328659058\n",
            "Epoch :  101 \t test loss : 0.5623297095298767 \t train loss 0.5605360269546509\n",
            "Model 4 0.749\n",
            "Epoch :  1 \t test loss : 0.7226935625076294 \t train loss 0.7773838043212891\n",
            "Epoch :  101 \t test loss : 0.6040113568305969 \t train loss 0.6039559841156006\n",
            "Model 5 0.721\n",
            "Epoch :  1 \t test loss : 0.8676765561103821 \t train loss 1.2296435832977295\n",
            "Epoch :  101 \t test loss : 0.5916852355003357 \t train loss 0.5900984406471252\n",
            "Model 6 0.7170000000000001\n",
            "Epoch :  1 \t test loss : 0.7014631032943726 \t train loss 0.8131251335144043\n",
            "Epoch :  101 \t test loss : 0.6236663460731506 \t train loss 0.6303722858428955\n",
            "Model 7 0.6970000000000001\n",
            "Epoch :  1 \t test loss : 0.702407717704773 \t train loss 0.7432264685630798\n",
            "Epoch :  101 \t test loss : 0.6251105070114136 \t train loss 0.6084132194519043\n",
            "Model 8 0.726\n",
            "Epoch :  1 \t test loss : 0.6917037963867188 \t train loss 0.8033823370933533\n",
            "Epoch :  101 \t test loss : 0.6257200837135315 \t train loss 0.650871992111206\n",
            "Model 9 0.723\n",
            "Epoch :  1 \t test loss : 0.6946837306022644 \t train loss 0.9384831786155701\n",
            "Epoch :  101 \t test loss : 0.6169061064720154 \t train loss 0.5923759937286377\n",
            "Model 10 0.688\n",
            "Epoch :  1 \t test loss : 0.6934367418289185 \t train loss 0.6849638819694519\n",
            "Epoch :  101 \t test loss : 0.6929139494895935 \t train loss 0.6849326491355896\n",
            "Model 11 0.5329999999999999\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.7046473026275635\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 12 0.5329999999999999\n",
            "Epoch :  1 \t test loss : 0.7943721413612366 \t train loss 0.8404093980789185\n",
            "Epoch :  101 \t test loss : 0.7401660680770874 \t train loss 0.2860028147697449\n",
            "Model 13 0.742\n",
            "Epoch :  1 \t test loss : 0.8899211287498474 \t train loss 1.013197660446167\n",
            "Epoch :  101 \t test loss : 0.7125673294067383 \t train loss 0.24923013150691986\n",
            "Model 14 0.75\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 15 0.5329999999999999\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 16 0.5329999999999999\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 17 0.5329999999999999\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 18 0.5329999999999999\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 19 0.5329999999999999\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 20 0.5329999999999999\n",
            "Epoch :  1 \t test loss : 0.7315757870674133 \t train loss 0.8396854400634766\n",
            "Epoch :  101 \t test loss : 0.6865434646606445 \t train loss 0.696877121925354\n",
            "Model 1 0.667\n",
            "Epoch :  1 \t test loss : 0.6876327991485596 \t train loss 0.6994264721870422\n",
            "Epoch :  101 \t test loss : 0.5427722334861755 \t train loss 0.6230794191360474\n",
            "Model 2 0.769\n",
            "Epoch :  1 \t test loss : 0.6960902810096741 \t train loss 0.7313265800476074\n",
            "Epoch :  101 \t test loss : 0.6154512763023376 \t train loss 0.641185998916626\n",
            "Model 3 0.765\n",
            "Epoch :  1 \t test loss : 0.7299167513847351 \t train loss 1.031234860420227\n",
            "Epoch :  101 \t test loss : 0.6217771768569946 \t train loss 0.6286188364028931\n",
            "Model 4 0.724\n",
            "Epoch :  1 \t test loss : 0.684366762638092 \t train loss 0.6921151280403137\n",
            "Epoch :  101 \t test loss : 0.5798711180686951 \t train loss 0.5827100276947021\n",
            "Model 5 0.745\n",
            "Epoch :  1 \t test loss : 0.6897750496864319 \t train loss 0.7412210702896118\n",
            "Epoch :  101 \t test loss : 0.6352556943893433 \t train loss 0.6201268434524536\n",
            "Model 6 0.722\n",
            "Epoch :  1 \t test loss : 0.6807437539100647 \t train loss 0.7289837598800659\n",
            "Epoch :  101 \t test loss : 0.5828019380569458 \t train loss 0.6154152750968933\n",
            "Model 7 0.733\n",
            "Epoch :  1 \t test loss : 0.6929019689559937 \t train loss 0.7768840789794922\n",
            "Epoch :  101 \t test loss : 0.5995355844497681 \t train loss 0.6265814900398254\n",
            "Model 8 0.721\n",
            "Epoch :  1 \t test loss : 0.6972659826278687 \t train loss 0.8182465434074402\n",
            "Epoch :  101 \t test loss : 0.6036311984062195 \t train loss 0.6286957859992981\n",
            "Model 9 0.725\n",
            "Epoch :  1 \t test loss : 0.6868447065353394 \t train loss 1.0529407262802124\n",
            "Epoch :  101 \t test loss : 0.6220741868019104 \t train loss 0.6408964395523071\n",
            "Model 10 0.702\n",
            "Epoch :  1 \t test loss : 0.6859413981437683 \t train loss 0.6922127604484558\n",
            "Epoch :  101 \t test loss : 0.6871789693832397 \t train loss 0.6906949281692505\n",
            "Model 11 0.56\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6926441192626953\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 12 0.56\n",
            "Epoch :  1 \t test loss : 1.88109290599823 \t train loss 2.015509843826294\n",
            "Epoch :  101 \t test loss : 0.8968787789344788 \t train loss 0.45403897762298584\n",
            "Model 13 0.6890000000000001\n",
            "Epoch :  1 \t test loss : 1.4507126808166504 \t train loss 1.6496615409851074\n",
            "Epoch :  101 \t test loss : 0.7090486288070679 \t train loss 0.4422318637371063\n",
            "Model 14 0.7010000000000001\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 15 0.56\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 16 0.56\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 17 0.56\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 18 0.56\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 19 0.56\n",
            "Epoch :  1 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Epoch :  101 \t test loss : 0.6931474208831787 \t train loss 0.6931474208831787\n",
            "Model 20 0.56\n",
            "It took 12.860085920492809 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbnkSAze_9oQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "209d4ad2-c82c-463f-e5ff-fcbd2999633e"
      },
      "source": [
        "accuracies.mean(1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6335, 0.7170, 0.7292, 0.7345, 0.7352, 0.7283, 0.7240, 0.7260, 0.7345,\n",
              "        0.7130, 0.5505, 0.5975, 0.7283, 0.7358, 0.5505, 0.5505, 0.5505, 0.5505,\n",
              "        0.5505, 0.5505])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fO9c8gx_9oT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "da267b96-e930-407b-c157-f3a166241846"
      },
      "source": [
        "accuracies.std(1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0985, 0.0385, 0.0268, 0.0197, 0.0102, 0.0122, 0.0180, 0.0041, 0.0231,\n",
              "        0.0231, 0.0121, 0.0958, 0.0266, 0.0271, 0.0121, 0.0121, 0.0121, 0.0121,\n",
              "        0.0121, 0.0121])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4vn3NHpQ2Pz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe8eed24-6d18-48cc-bb7e-71aa32b6b34a"
      },
      "source": [
        "len(auxs)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjC6GKEUZAPb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df5a5243-46b9-4e28-e184-704b37da72a7"
      },
      "source": [
        "epochs = 400\n",
        "accuracies_aux = torch.empty(5, 4, dtype=torch.float)\n",
        "\n",
        "start = time.time()\n",
        "for i in range(4):\n",
        "     train_input, train_target, train_classes, test_input, test_target, test_classes = prolog.generate_pair_sets(1000)\n",
        "     train_input_aux = train_input.view(-1, 14, 14).unsqueeze(1).cuda()\n",
        "     test_input_aux = test_input.view(-1, 14, 14).unsqueeze(1).cuda()\n",
        "     train_classes_aux = train_classes.view(2000).cuda()\n",
        "     test_classes_aux = test_classes.view(2000).cuda()\n",
        "     test_target = test_target.cuda()\n",
        "     for j in range(5):\n",
        "        _, _, _, best_accuracy = train_model_aux(auxs[j], train_input_aux, train_classes_aux, test_input_aux, test_target, test_classes_aux, \\\n",
        "                                                 epochs = epochs, lr = 0.01)\n",
        "        print('Model', j+1 , best_accuracy)\n",
        "        accuracies_aux[j][i] = best_accuracy\n",
        "\n",
        "\n",
        "minute = (time.time()-start) / 60\n",
        "print('It took', minute, 'minutes.')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch :  1 \t test loss : 17.545307159423828 \t train loss 17.64027976989746\n",
            "Epoch :  101 \t test loss : 2.3030121326446533 \t train loss 2.298919200897217\n",
            "Epoch :  201 \t test loss : 2.3031198978424072 \t train loss 2.2989156246185303\n",
            "Epoch :  301 \t test loss : 2.303117513656616 \t train loss 2.298915386199951\n",
            "Model 1 0.5640000000000001\n",
            "Epoch :  1 \t test loss : 6.267399311065674 \t train loss 6.823856830596924\n",
            "Epoch :  101 \t test loss : 2.160560369491577 \t train loss 2.1772992610931396\n",
            "Epoch :  201 \t test loss : 2.1108527183532715 \t train loss 2.120410442352295\n",
            "Epoch :  301 \t test loss : 2.0870611667633057 \t train loss 2.0540316104888916\n",
            "Model 2 0.654\n",
            "Epoch :  1 \t test loss : 8.222110748291016 \t train loss 7.6644110679626465\n",
            "Epoch :  101 \t test loss : 2.144181251525879 \t train loss 2.140069007873535\n",
            "Epoch :  201 \t test loss : 1.7356529235839844 \t train loss 1.7112184762954712\n",
            "Epoch :  301 \t test loss : 1.4589918851852417 \t train loss 1.4491063356399536\n",
            "Model 3 0.738\n",
            "Epoch :  1 \t test loss : 7.105202674865723 \t train loss 7.14387321472168\n",
            "Epoch :  101 \t test loss : 1.2707182168960571 \t train loss 1.2233258485794067\n",
            "Epoch :  201 \t test loss : 1.0697036981582642 \t train loss 1.0190575122833252\n",
            "Epoch :  301 \t test loss : 1.0175329446792603 \t train loss 1.0013608932495117\n",
            "Model 4 0.808\n",
            "Epoch :  1 \t test loss : 11.27068042755127 \t train loss 11.369600296020508\n",
            "Epoch :  101 \t test loss : 1.3054158687591553 \t train loss 1.2685468196868896\n",
            "Epoch :  201 \t test loss : 1.1318066120147705 \t train loss 1.0435410737991333\n",
            "Epoch :  301 \t test loss : 1.07086980342865 \t train loss 0.9518781900405884\n",
            "Model 5 0.8160000000000001\n",
            "Epoch :  1 \t test loss : 2.3236606121063232 \t train loss 2.327866315841675\n",
            "Epoch :  101 \t test loss : 2.301913261413574 \t train loss 2.300279378890991\n",
            "Epoch :  201 \t test loss : 2.3019208908081055 \t train loss 2.300279140472412\n",
            "Epoch :  301 \t test loss : 2.30192232131958 \t train loss 2.3002800941467285\n",
            "Model 1 0.536\n",
            "Epoch :  1 \t test loss : 2.5505988597869873 \t train loss 2.523858070373535\n",
            "Epoch :  101 \t test loss : 1.7918188571929932 \t train loss 1.8144758939743042\n",
            "Epoch :  201 \t test loss : 1.6190743446350098 \t train loss 1.6119645833969116\n",
            "Epoch :  301 \t test loss : 1.5659444332122803 \t train loss 1.594254493713379\n",
            "Model 2 0.704\n",
            "Epoch :  1 \t test loss : 4.359550952911377 \t train loss 4.621927261352539\n",
            "Epoch :  101 \t test loss : 1.6519674062728882 \t train loss 1.6631911993026733\n",
            "Epoch :  201 \t test loss : 1.3815754652023315 \t train loss 1.3701852560043335\n",
            "Epoch :  301 \t test loss : 1.2453199625015259 \t train loss 1.2352886199951172\n",
            "Model 3 0.767\n",
            "Epoch :  1 \t test loss : 9.62988567352295 \t train loss 8.709488868713379\n",
            "Epoch :  101 \t test loss : 1.5940864086151123 \t train loss 1.5869648456573486\n",
            "Epoch :  201 \t test loss : 1.237208604812622 \t train loss 1.1779382228851318\n",
            "Epoch :  301 \t test loss : 1.0918711423873901 \t train loss 1.0205827951431274\n",
            "Model 4 0.8049999999999999\n",
            "Epoch :  1 \t test loss : 4.792321681976318 \t train loss 4.437352180480957\n",
            "Epoch :  101 \t test loss : 1.1821072101593018 \t train loss 1.144318699836731\n",
            "Epoch :  201 \t test loss : 1.0566457509994507 \t train loss 0.9244109988212585\n",
            "Epoch :  301 \t test loss : 0.9493227005004883 \t train loss 0.8410517573356628\n",
            "Model 5 0.833\n",
            "Epoch :  1 \t test loss : 2.3030266761779785 \t train loss 2.3090381622314453\n",
            "Epoch :  101 \t test loss : 2.2985363006591797 \t train loss 2.2989895343780518\n",
            "Epoch :  201 \t test loss : 2.2985360622406006 \t train loss 2.298989772796631\n",
            "Epoch :  301 \t test loss : 2.298537254333496 \t train loss 2.298989772796631\n",
            "Model 1 0.525\n",
            "Epoch :  1 \t test loss : 5.949851036071777 \t train loss 5.9542622566223145\n",
            "Epoch :  101 \t test loss : 1.7436481714248657 \t train loss 1.7076538801193237\n",
            "Epoch :  201 \t test loss : 1.571790337562561 \t train loss 1.5592283010482788\n",
            "Epoch :  301 \t test loss : 1.5357407331466675 \t train loss 1.489969253540039\n",
            "Model 2 0.728\n",
            "Epoch :  1 \t test loss : 8.533239364624023 \t train loss 7.7978081703186035\n",
            "Epoch :  101 \t test loss : 1.7303372621536255 \t train loss 1.6923459768295288\n",
            "Epoch :  201 \t test loss : 1.3541233539581299 \t train loss 1.341586709022522\n",
            "Epoch :  301 \t test loss : 1.3247143030166626 \t train loss 1.2692081928253174\n",
            "Model 3 0.76\n",
            "Epoch :  1 \t test loss : 5.55018424987793 \t train loss 5.659510612487793\n",
            "Epoch :  101 \t test loss : 1.3183785676956177 \t train loss 1.3033887147903442\n",
            "Epoch :  201 \t test loss : 1.0660359859466553 \t train loss 1.0281033515930176\n",
            "Epoch :  301 \t test loss : 0.9787659049034119 \t train loss 0.9033706188201904\n",
            "Model 4 0.829\n",
            "Epoch :  1 \t test loss : 21.908132553100586 \t train loss 22.385814666748047\n",
            "Epoch :  101 \t test loss : 1.5309138298034668 \t train loss 1.5844722986221313\n",
            "Epoch :  201 \t test loss : 1.2253233194351196 \t train loss 1.1417808532714844\n",
            "Epoch :  301 \t test loss : 1.0744012594223022 \t train loss 1.002282738685608\n",
            "Model 5 0.8160000000000001\n",
            "Epoch :  1 \t test loss : 2.3043296337127686 \t train loss 2.305997848510742\n",
            "Epoch :  101 \t test loss : 2.3027374744415283 \t train loss 2.2988548278808594\n",
            "Epoch :  201 \t test loss : 2.3027420043945312 \t train loss 2.2988550662994385\n",
            "Epoch :  301 \t test loss : 2.302741765975952 \t train loss 2.2988548278808594\n",
            "Model 1 0.567\n",
            "Epoch :  1 \t test loss : 5.911566257476807 \t train loss 5.613497734069824\n",
            "Epoch :  101 \t test loss : 1.9737812280654907 \t train loss 1.9504212141036987\n",
            "Epoch :  201 \t test loss : 1.657444715499878 \t train loss 1.632072925567627\n",
            "Epoch :  301 \t test loss : 1.5764073133468628 \t train loss 1.5358152389526367\n",
            "Model 2 0.712\n",
            "Epoch :  1 \t test loss : 9.855782508850098 \t train loss 9.868197441101074\n",
            "Epoch :  101 \t test loss : 1.6695575714111328 \t train loss 1.6611206531524658\n",
            "Epoch :  201 \t test loss : 1.3310785293579102 \t train loss 1.333633542060852\n",
            "Epoch :  301 \t test loss : 1.261993646621704 \t train loss 1.2643382549285889\n",
            "Model 3 0.769\n",
            "Epoch :  1 \t test loss : 12.129673957824707 \t train loss 12.139198303222656\n",
            "Epoch :  101 \t test loss : 1.437191128730774 \t train loss 1.408713698387146\n",
            "Epoch :  201 \t test loss : 1.141233205795288 \t train loss 1.0737507343292236\n",
            "Epoch :  301 \t test loss : 1.1163887977600098 \t train loss 0.9995311498641968\n",
            "Model 4 0.806\n",
            "Epoch :  1 \t test loss : 6.557125091552734 \t train loss 6.283068656921387\n",
            "Epoch :  101 \t test loss : 1.2154909372329712 \t train loss 1.2122362852096558\n",
            "Epoch :  201 \t test loss : 1.0039515495300293 \t train loss 0.9463104605674744\n",
            "Epoch :  301 \t test loss : 0.9445744752883911 \t train loss 0.8615813255310059\n",
            "Model 5 0.834\n",
            "It took 10.170110551516215 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0hjOhkMt5Ob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}